

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Append Distribution &mdash; Citus 5.2.1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="top" title="Citus 5.2.1 documentation" href="../index.html"/>
        <link rel="next" title="Frequently Asked Questions" href="../faq/faq.html"/>
        <link rel="prev" title="Configuration Reference" href="configuration.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
   window.intercomSettings = {
     app_id: "jfost7ih",
   };
  </script>
  <script>(function(){var w=window;var ic=w.Intercom;if(typeof ic==="function"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='https://widget.intercom.io/widget/jfost7ih';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}}})()</script>
</head>

<body class="wy-body-for-nav" role="document">
  <div class="header">
  <div class="section-wrap"> 
              <div class="utility-nav">
              </div>
                      <a href="https://www.citusdata.com" title="Citus Data" rel="home" class="logo">
            <img src="../_static/images/citus-logo.png" alt="Citus Data">
          </a>
              <div class="clear"></div>
  </div>
  </div>
  <div class="nav-wrap menu">
    <div class="section-wrap">
      <ul>
        <li><a href="https://www.citusdata.com/product/citus">Product</a></li>
        <li><a href="https://www.citusdata.com/solutions/applications">Solutions</a></li>
        <li><a href="https://www.citusdata.com/blog">Blog</a></li>
        <li><a href="#">Documentation</a></li>
      </ul>
    </div>
  </div>

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Citus
          

          
          </a>

          
            
            
              <div class="version">
                5.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">About Citus</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../aboutcitus/what_is_citus.html">What is Citus?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../aboutcitus/introduction_to_citus.html">Architecture</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorial</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tut-hash-distribution.html">Hash-Distributed Data</a></li>
</ul>
<p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/requirements.html">Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/development.html">Single-Machine Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/production.html">Multi-Machine Cluster</a></li>
</ul>
<p class="caption"><span class="caption-text">Distributed Tables</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dist_tables/concepts.html">Picking a Distribution Column</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dist_tables/ddl.html">Creating Distributed Tables (DDL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dist_tables/dml.html">Ingesting, Modifying Data (DML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dist_tables/querying.html">Querying Distributed Tables (SQL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dist_tables/extensions.html">PostgreSQL extensions</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../performance/query_processing.html">Citus Query Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance/scaling_data_ingestion.html">Scaling Out Data Ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance/performance_tuning.html">Query Performance Tuning</a></li>
</ul>
<p class="caption"><span class="caption-text">Cloud</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cloud/index.html">Citus Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cloud/features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cloud/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cloud/support.html">Support and Billing</a></li>
</ul>
<p class="caption"><span class="caption-text">Technical Solutions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tech_soln/real_time_dashboards.html">Real Time Dashboards</a></li>
</ul>
<p class="caption"><span class="caption-text">Administration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../admin_guide/cluster_management.html">Cluster Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../admin_guide/upgrading_citus.html">Upgrading Citus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../admin_guide/transitioning_from_postgresql_to_citus.html">Transitioning From PostgreSQL to Citus</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="citus_sql_reference.html">Citus SQL Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="sql_workarounds.html">SQL Workarounds</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_defined_functions.html">User Defined Functions Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="metadata_tables.html">Metadata Tables Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration Reference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Append Distribution</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#creating-and-distributing-tables">Creating and Distributing Tables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#expiring-data">Expiring Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deleting-data">Deleting Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dropping-tables">Dropping Tables</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-loading">Data Loading</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#bulk-load-using-copy">Bulk load using \copy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#incremental-loads-by-appending-to-existing-shards">Incremental loads by appending to existing shards</a></li>
<li class="toctree-l3"><a class="reference internal" href="#increasing-data-loading-performance">Increasing data loading performance</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scaling-data-ingestion">Scaling Data Ingestion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#master-node-bulk-ingestion-100k-s-200k-s">Master Node Bulk Ingestion (100k/s-200k/s)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#worker-node-bulk-ingestion-100k-s-1m-s">Worker Node Bulk Ingestion (100k/s-1M/s)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pre-processing-data-in-citus">Pre-processing Data in Citus</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/faq.html">Frequently Asked Questions</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <a href="../index.html">Citus</a>
      <ul>
        <li><a href="/product/citus">Product</a></li>
        <li><a href="/solutions/applications">Solutions</a></li>
        <li><a href="/blog">Blog</a></li>
      </ul>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Append Distribution</li>
    <li class="wy-breadcrumbs-aside">
      
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="append-distribution">
<span id="id1"></span><h1>Append Distribution<a class="headerlink" href="#append-distribution" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Append distribution is a specialized technique which requires
care to use efficiently. Hash distribution is a better choice
for most situations.</p>
</div>
<p>While Citus&#8217; most common use cases involve hash data distribution,
it can also distribute timeseries data across a variable number of
shards by their order in time. This section provides a short reference
to loading, deleting, and maninpulating timeseries data.</p>
<p>As the name suggests, append based distribution is more suited to
append-only use cases. This typically includes event based data
which arrives in a time-ordered series. You can then distribute
your largest tables by time, and batch load your events into Citus
in intervals of N minutes. This data model can be generalized to a
number of time series use cases; for example, each line in a website&#8217;s
log file, machine activity logs or aggregated website events. Append
based distribution supports more efficient range queries. This is
because given a range query on the distribution key, the Citus query
planner can easily determine which shards overlap that range and
send the query to only to relevant shards.</p>
<p>Hash based distribution is more suited to cases where you want to
do real-time inserts along with analytics on your data or want to
distribute by a non-ordered column (eg. user id). This data model
is relevant for real-time analytics use cases; for example, actions
in a mobile application, user website events, or social media
analytics. In this case, Citus will maintain minimum and maximum
hash ranges for all the created shards. Whenever a row is inserted,
updated or deleted, Citus will redirect the query to the correct
shard and issue it locally. This data model is more suited for doing
co-located joins and for queries involving equality based filters
on the distribution column.</p>
<p>Citus uses slightly different syntaxes for creation and manipulation
of append and hash distributed tables. Also, the operations supported
on the tables differ based on the distribution method chosen. In the
sections that follow, we describe the syntax for creating append
distributed tables, and also describe the operations which can be
done on them.</p>
<div class="section" id="creating-and-distributing-tables">
<h2>Creating and Distributing Tables<a class="headerlink" href="#creating-and-distributing-tables" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The instructions below assume that the PostgreSQL installation is in your path. If not, you will need to add it to your PATH environment variable. For example:</p>
<div class="last highlight-default"><div class="highlight"><pre><span></span>export PATH=/usr/lib/postgresql/9.5/:$PATH
</pre></div>
</div>
</div>
<p>We use the github events dataset to illustrate the commands below. You can download that dataset by running:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">examples</span><span class="o">.</span><span class="n">citusdata</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">github_archive</span><span class="o">/</span><span class="n">github_events</span><span class="o">-</span><span class="mi">2015</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="p">{</span><span class="mf">0.</span><span class="o">.</span><span class="mi">5</span><span class="p">}</span><span class="o">.</span><span class="n">csv</span><span class="o">.</span><span class="n">gz</span>
<span class="n">gzip</span> <span class="o">-</span><span class="n">d</span> <span class="n">github_events</span><span class="o">-</span><span class="mi">2015</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span><span class="o">-*.</span><span class="n">gz</span>
</pre></div>
</div>
<p>To create an append distributed table, you need to first define the table schema. To do so, you can define a table using the <a class="reference external" href="http://www.postgresql.org/docs/9.5/static/sql-createtable.html">CREATE TABLE</a> statement in the same way as you would do with a regular PostgreSQL table.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">psql</span> <span class="o">-</span><span class="n">h</span> <span class="n">localhost</span> <span class="o">-</span><span class="n">d</span> <span class="n">postgres</span>
<span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">github_events</span>
<span class="p">(</span>
    <span class="n">event_id</span> <span class="n">bigint</span><span class="p">,</span>
    <span class="n">event_type</span> <span class="n">text</span><span class="p">,</span>
    <span class="n">event_public</span> <span class="n">boolean</span><span class="p">,</span>
    <span class="n">repo_id</span> <span class="n">bigint</span><span class="p">,</span>
    <span class="n">payload</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">repo</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">actor</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">org</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">created_at</span> <span class="n">timestamp</span>
<span class="p">);</span>
</pre></div>
</div>
<p>Next, you can use the master_create_distributed_table() function to mark the table as an append distributed table and specify its distribution column.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">SELECT</span> <span class="n">master_create_distributed_table</span><span class="p">(</span><span class="s1">&#39;github_events&#39;</span><span class="p">,</span> <span class="s1">&#39;created_at&#39;</span><span class="p">,</span> <span class="s1">&#39;append&#39;</span><span class="p">);</span>
</pre></div>
</div>
<p>This function informs Citus that the github_events table should be distributed by append on the created_at column. Note that this method doesn&#8217;t enforce a particular distribution; it merely tells the database to keep minimum and maximum values for the created_at column in each shard which are later used by the database for optimizing queries.</p>
</div>
<div class="section" id="expiring-data">
<h2>Expiring Data<a class="headerlink" href="#expiring-data" title="Permalink to this headline">¶</a></h2>
<p>In append distribution, users typically want to track data only for the last few months / years. In such cases, the shards that are no longer needed still occupy disk space. To address this, Citus provides a user defined function master_apply_delete_command() to delete old shards. The function takes a <a class="reference external" href="http://www.postgresql.org/docs/9.5/static/sql-delete.html">DELETE</a> command as input and deletes all the shards that match the delete criteria with their metadata.</p>
<p>The function uses shard metadata to decide whether or not a shard needs to be deleted, so it requires the WHERE clause in the DELETE statement to be on the distribution column. If no condition is specified, then all shards are selected for deletion. The UDF then connects to the worker nodes and issues DROP commands for all the shards which need to be deleted. If a drop query for a particular shard replica fails, then that replica is marked as TO DELETE. The shard replicas which are marked as TO DELETE are not considered for future queries and can be cleaned up later.</p>
<p>The example below deletes those shards from the github_events table which have all rows with created_at &gt;= &#8216;2015-01-01 00:00:00&#8217;. Note that the table is distributed on the created_at column.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">SELECT</span> <span class="o">*</span> <span class="kn">from</span> <span class="nn">master_apply_delete_command</span><span class="p">(</span><span class="s1">&#39;DELETE FROM github_events WHERE created_at &gt;= &#39;&#39;2015-01-01 00:00:00&#39;&#39;&#39;</span><span class="p">);</span>
 <span class="n">master_apply_delete_command</span>
<span class="o">-----------------------------</span>
                           <span class="mi">3</span>
<span class="p">(</span><span class="mi">1</span> <span class="n">row</span><span class="p">)</span>
</pre></div>
</div>
<p>To learn more about the function, its arguments and its usage, please visit the <a class="reference internal" href="user_defined_functions.html#user-defined-functions"><span class="std std-ref">User Defined Functions Reference</span></a> section of our documentation.  Please note that this function only deletes complete shards and not individual rows from shards. If your use case requires deletion of individual rows in real-time, see the section below about deleting data.</p>
</div>
<div class="section" id="deleting-data">
<h2>Deleting Data<a class="headerlink" href="#deleting-data" title="Permalink to this headline">¶</a></h2>
<p>The most flexible way to modify or delete rows throughout a Citus cluster is the master_modify_multiple_shards command. It takes a regular SQL statement as argument and runs it on all workers:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">SELECT</span> <span class="n">master_modify_multiple_shards</span><span class="p">(</span>
  <span class="s1">&#39;DELETE FROM github_events WHERE created_at &gt;= &#39;&#39;2015-01-01 00:00:00&#39;&#39;&#39;</span><span class="p">);</span>
</pre></div>
</div>
<p>The function uses a configurable commit protocol to update or delete data safely across multiple shards. Unlike master_apply_delete_command, it works at the row- rather than shard-level to modify or delete all rows that match the condition in the where clause. It deletes rows regardless of whether they comprise an entire shard. To learn more about the function, its arguments and its usage, please visit the <a class="reference internal" href="user_defined_functions.html#user-defined-functions"><span class="std std-ref">User Defined Functions Reference</span></a> section of our documentation.</p>
</div>
<div class="section" id="dropping-tables">
<h2>Dropping Tables<a class="headerlink" href="#dropping-tables" title="Permalink to this headline">¶</a></h2>
<p>You can use the standard PostgreSQL <a class="reference external" href="http://www.postgresql.org/docs/9.5/static/sql-droptable.html">DROP TABLE</a>
command to remove your append distributed tables. As with regular tables, DROP TABLE removes any
indexes, rules, triggers, and constraints that exist for the target table. In addition, it also
drops the shards on the worker nodes and cleans up their metadata.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">DROP</span> <span class="n">TABLE</span> <span class="n">github_events</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="data-loading">
<h2>Data Loading<a class="headerlink" href="#data-loading" title="Permalink to this headline">¶</a></h2>
<p>Citus supports two methods to load data into your append distributed tables. The first one is suitable for bulk loads from files and involves using the \copy command. For use cases requiring smaller, incremental data loads, Citus provides two user defined functions. We describe each of the methods and their usage below.</p>
<div class="section" id="bulk-load-using-copy">
<h3>Bulk load using \copy<a class="headerlink" href="#bulk-load-using-copy" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="http://www.postgresql.org/docs/current/static/app-psql.html#APP-PSQL-META-COMMANDS-COPY">\copy</a>
command is used to copy data from a file to a distributed table while handling
replication and failures automatically. You can also use the server side <a class="reference external" href="http://www.postgresql.org/docs/current/static/sql-copy.html">COPY command</a>.
In the examples, we use the \copy command from psql, which sends a COPY .. FROM STDIN to the server and reads files on the client side, whereas COPY from a file would read the file on the server.</p>
<p>You can use \copy both on the master and from any of the workers. When using it from the worker, you need to add the master_host option. Behind the scenes, \copy first opens a connection to the master using the provided master_host option and uses master_create_empty_shard to create a new shard. Then, the command connects to the workers and copies data into the replicas until the size reaches shard_max_size, at which point another new shard is created. Finally, the command fetches statistics for the shards and updates the metadata.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">SET</span> <span class="n">citus</span><span class="o">.</span><span class="n">shard_max_size</span> <span class="n">TO</span> <span class="s1">&#39;64MB&#39;</span><span class="p">;</span>
\<span class="n">copy</span> <span class="n">github_events</span> <span class="kn">from</span> <span class="s1">&#39;github_events-2015-01-01-0.csv&#39;</span> <span class="n">WITH</span> <span class="p">(</span><span class="nb">format</span> <span class="n">CSV</span><span class="p">,</span> <span class="n">master_host</span> <span class="s1">&#39;master-host-101&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Citus assigns a unique shard id to each new shard and all its replicas have the same shard id. Each shard is represented on the worker node as a regular PostgreSQL table with name &#8216;tablename_shardid&#8217; where tablename is the name of the distributed table and shardid is the unique id assigned to that shard. One can connect to the worker postgres instances to view or run commands on individual shards.</p>
<p>By default, the \copy command depends on two configuration parameters for its behavior. These are called citus.shard_max_size and citus.shard_replication_factor.</p>
<ol class="arabic simple">
<li><strong>citus.shard_max_size :-</strong> This parameter determines the maximum size of a shard created using \copy, and defaults to 1 GB. If the file is larger than this parameter, \copy will break it up into multiple shards.</li>
<li><strong>citus.shard_replication_factor :-</strong> This parameter determines the number of nodes each shard gets replicated to, and defaults to two. The ideal value for this parameter depends on the size of the cluster and rate of node failure. For example, you may want to increase the replication factor if you run large clusters and observe node failures on a more frequent basis.</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The configuration setting citus.shard_replication_factor can only be set on the master node.</p>
</div>
<p>Please note that you can load several files in parallel through separate database connections or from different nodes. It is also worth noting that \copy always creates at least one shard and does not append to existing shards. You can use the method described below to append to previously created shards.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>There is no notion of snapshot isolation across shards, which means that a multi-shard SELECT that runs concurrently with a COPY might see it committed on some shards, but not on others. If the user is storing events data, he may occasionally observe small gaps in recent data. It is up to applications to deal with this if it is a problem (e.g.  exclude the most recent data from queries, or use some lock).</p>
<p class="last">If COPY fails to open a connection for a shard placement then it behaves in the same way as INSERT, namely to mark the placement(s) as inactive unless there are no more active placements. If any other failure occurs after connecting, the transaction is rolled back and thus no metadata changes are made.</p>
</div>
</div>
<div class="section" id="incremental-loads-by-appending-to-existing-shards">
<h3>Incremental loads by appending to existing shards<a class="headerlink" href="#incremental-loads-by-appending-to-existing-shards" title="Permalink to this headline">¶</a></h3>
<p>The \copy command always creates a new shard when it is used and is best suited for bulk loading of data. Using \copy to load smaller data increments will result in many small shards which might not be ideal. In order to allow smaller, incremental loads into append distributed tables, Citus provides 2 user defined functions. They are master_create_empty_shard() and master_append_table_to_shard().</p>
<p>master_create_empty_shard() can be used to create new empty shards for a table. This function also replicates the empty shard to citus.shard_replication_factor number of nodes like the \copy command.</p>
<p>master_append_table_to_shard() can be used to append the contents of a PostgreSQL table to an existing shard. This allows the user to control the shard to which the rows will be appended. It also returns the shard fill ratio which helps to make a decision on whether more data should be appended to this shard or if a new shard should be created.</p>
<p>To use the above functionality, you can first insert incoming data into a regular PostgreSQL table. You can then create an empty shard using master_create_empty_shard(). Then, using master_append_table_to_shard(), you can append the contents of the staging table to the specified shard, and then subsequently delete the data from the staging table. Once the shard fill ratio returned by the append function becomes close to 1, you can create a new shard and start appending to the new one.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">SELECT</span> <span class="o">*</span> <span class="kn">from</span> <span class="nn">master_create_empty_shard</span><span class="p">(</span><span class="s1">&#39;github_events&#39;</span><span class="p">);</span>
<span class="n">master_create_empty_shard</span>
<span class="o">---------------------------</span>
                <span class="mi">102089</span>
<span class="p">(</span><span class="mi">1</span> <span class="n">row</span><span class="p">)</span>

<span class="n">SELECT</span> <span class="o">*</span> <span class="kn">from</span> <span class="nn">master_append_table_to_shard</span><span class="p">(</span><span class="mi">102089</span><span class="p">,</span> <span class="s1">&#39;github_events_temp&#39;</span><span class="p">,</span> <span class="s1">&#39;master-101&#39;</span><span class="p">,</span> <span class="mi">5432</span><span class="p">);</span>
<span class="n">master_append_table_to_shard</span>
<span class="o">------------------------------</span>
        <span class="mf">0.100548</span>
<span class="p">(</span><span class="mi">1</span> <span class="n">row</span><span class="p">)</span>
</pre></div>
</div>
<p>To learn more about the two UDFs, their arguments and usage, please visit the <a class="reference internal" href="user_defined_functions.html#user-defined-functions"><span class="std std-ref">User Defined Functions Reference</span></a> section of the documentation.</p>
</div>
<div class="section" id="increasing-data-loading-performance">
<h3>Increasing data loading performance<a class="headerlink" href="#increasing-data-loading-performance" title="Permalink to this headline">¶</a></h3>
<p>The methods described above enable you to achieve high bulk load rates which are sufficient for most use cases. If you require even higher data load rates, you can use the functions described above in several ways and write scripts to better control sharding and data loading. The next section explains how to go even faster.</p>
</div>
</div>
<div class="section" id="scaling-data-ingestion">
<h2>Scaling Data Ingestion<a class="headerlink" href="#scaling-data-ingestion" title="Permalink to this headline">¶</a></h2>
<p>If your use-case does not require real-time ingests, then using append distributed tables will give you the highest ingest rates. This approach is more suitable for use-cases which use time-series data and where the database can be a few minutes or more behind.</p>
<div class="section" id="master-node-bulk-ingestion-100k-s-200k-s">
<h3>Master Node Bulk Ingestion (100k/s-200k/s)<a class="headerlink" href="#master-node-bulk-ingestion-100k-s-200k-s" title="Permalink to this headline">¶</a></h3>
<p>To ingest data into an append distributed table, you can use the <a class="reference external" href="http://www.postgresql.org/docs/current/static/sql-copy.html">COPY</a> command, which will create a new shard out of the data you ingest. COPY can break up files larger than the configured citus.shard_max_size into multiple shards. COPY for append distributed tables only opens connections for the new shards, which means it behaves a bit differently than COPY for hash distributed tables, which may open connections for all shards. A COPY for append distributed tables command does not ingest rows in parallel over many connections, but it is safe to run many commands in parallel.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Set</span> <span class="n">up</span> <span class="n">the</span> <span class="n">events</span> <span class="n">table</span>
<span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">events</span> <span class="p">(</span><span class="n">time</span> <span class="n">timestamp</span><span class="p">,</span> <span class="n">data</span> <span class="n">jsonb</span><span class="p">);</span>
<span class="n">SELECT</span> <span class="n">master_create_distributed_table</span><span class="p">(</span><span class="s1">&#39;events&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;append&#39;</span><span class="p">);</span>

<span class="o">--</span> <span class="n">Add</span> <span class="n">data</span> <span class="n">into</span> <span class="n">a</span> <span class="n">new</span> <span class="n">staging</span> <span class="n">table</span>
\<span class="n">COPY</span> <span class="n">events</span> <span class="n">FROM</span> <span class="s1">&#39;path-to-csv-file&#39;</span> <span class="n">WITH</span> <span class="n">CSV</span>
</pre></div>
</div>
<p>COPY creates new shards every time it is used, which allows many files to be ingested simultaneously, but may cause issues if queries end up involving thousands of shards. An alternative way to ingest data is to append it to existing shards using the master_append_table_to_shard function. To use master_append_table_to_shard, the data needs to be loaded into a staging table and some custom logic to select an appropriate shard is required.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Prepare</span> <span class="n">a</span> <span class="n">staging</span> <span class="n">table</span>
<span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">stage_1</span> <span class="p">(</span><span class="n">LIKE</span> <span class="n">events</span><span class="p">);</span>
\<span class="n">COPY</span> <span class="n">stage_1</span> <span class="n">FROM</span> <span class="s1">&#39;path-to-csv-file WITH CSV</span>

<span class="o">--</span> <span class="n">In</span> <span class="n">a</span> <span class="n">separate</span> <span class="n">transaction</span><span class="p">,</span> <span class="n">append</span> <span class="n">the</span> <span class="n">staging</span> <span class="n">table</span>
<span class="n">SELECT</span> <span class="n">master_append_table_to_shard</span><span class="p">(</span><span class="n">select_events_shard</span><span class="p">(),</span> <span class="s1">&#39;stage_1&#39;</span><span class="p">,</span> <span class="s1">&#39;master-node&#39;</span><span class="p">,</span> <span class="mi">5432</span><span class="p">);</span>
</pre></div>
</div>
<p>An example of a shard selection function is given below. It appends to a shard until its size is greater than 1GB and then creates a new one, which has the drawback of only allowing one append at a time, but the advantage of bounding shard sizes.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>CREATE OR REPLACE FUNCTION select_events_shard() RETURNS bigint AS $$
DECLARE
  shard_id bigint;
BEGIN
  SELECT shardid INTO shard_id
  FROM pg_dist_shard JOIN pg_dist_shard_placement USING (shardid)
  WHERE logicalrelid = &#39;events&#39;::regclass AND shardlength &lt; 1024*1024*1024;

  IF shard_id IS NULL THEN
    /* no shard smaller than 1GB, create a new one */
    SELECT master_create_empty_shard(&#39;events&#39;) INTO shard_id;
  END IF;

  RETURN shard_id;
END;
$$ LANGUAGE plpgsql;
</pre></div>
</div>
<p>It may also be useful to create a sequence to generate a unique name for the staging table. This way each ingestion can be handled independently.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Create</span> <span class="n">stage</span> <span class="n">table</span> <span class="n">name</span> <span class="n">sequence</span>
<span class="n">CREATE</span> <span class="n">SEQUENCE</span> <span class="n">stage_id_sequence</span><span class="p">;</span>

<span class="o">--</span> <span class="n">Generate</span> <span class="n">a</span> <span class="n">stage</span> <span class="n">table</span> <span class="n">name</span>
<span class="n">SELECT</span> <span class="s1">&#39;stage_&#39;</span><span class="o">||</span><span class="n">nextval</span><span class="p">(</span><span class="s1">&#39;stage_id_sequence&#39;</span><span class="p">);</span>
</pre></div>
</div>
<p>To learn more about the master_append_table_to_shard and master_create_empty_shard UDFs, please visit the <a class="reference internal" href="user_defined_functions.html#user-defined-functions"><span class="std std-ref">User Defined Functions Reference</span></a> section of the documentation.</p>
</div>
<div class="section" id="worker-node-bulk-ingestion-100k-s-1m-s">
<h3>Worker Node Bulk Ingestion (100k/s-1M/s)<a class="headerlink" href="#worker-node-bulk-ingestion-100k-s-1m-s" title="Permalink to this headline">¶</a></h3>
<p>For very high data ingestion rates, data can be staged via the workers. This method scales out horizontally and provides the highest ingestion rates, but can be more complex to use. Hence, we recommend trying this method only if your data ingestion rates cannot be addressed by the previously described methods.</p>
<p>Append distributed tables support COPY via the worker, by specifying the address of the master in a master_host option, and optionally a master_port option (defaults to 5432). COPY via the workers has the same general properties as COPY via the master, except the initial parsing is not bottlenecked on the master.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">psql</span> <span class="o">-</span><span class="n">h</span> <span class="n">worker</span><span class="o">-</span><span class="n">node</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;\COPY events FROM &#39;data.csv&#39; WITH (FORMAT CSV, MASTER_HOST &#39;master-node&#39;)&quot;</span>
</pre></div>
</div>
<p>An alternative to using COPY is to create a staging table and use standard SQL clients to append it to the distributed table, which is similar to staging data via the master. An example of staging a file via a worker using psql is as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>stage_table=$(psql -tA -h worker-node-1 -c &quot;SELECT &#39;stage_&#39;||nextval(&#39;stage_id_sequence&#39;)&quot;)
psql -h worker-node-1 -c &quot;CREATE TABLE $stage_table (time timestamp, data jsonb)&quot;
psql -h worker-node-1 -c &quot;\COPY $stage_table FROM &#39;data.csv&#39; WITH CSV&quot;
psql -h master-node -c &quot;SELECT master_append_table_to_shard(choose_underutilized_shard(), &#39;$stage_table&#39;, &#39;worker-node-1&#39;, 5432)&quot;
psql -h worker-node-1 -c &quot;DROP TABLE $stage_table&quot;
</pre></div>
</div>
<p>The example above uses a choose_underutilized_shard function to select the shard to which to append. To ensure parallel data ingestion, this function should balance across many different shards.</p>
<p>An example choose_underutilized_shard function belows randomly picks one of the 20 smallest shards or creates a new one if there are less than 20 under 1GB. This allows 20 concurrent appends, which allows data ingestion of up to 1 million rows/s (depending on indexes, size, capacity).</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>/* Choose a shard to which to append */
CREATE OR REPLACE FUNCTION choose_underutilized_shard()
RETURNS bigint LANGUAGE plpgsql
AS $function$
DECLARE
  shard_id bigint;
  num_small_shards int;
BEGIN
  SELECT shardid, count(*) OVER () INTO shard_id, num_small_shards
  FROM pg_dist_shard JOIN pg_dist_shard_placement USING (shardid)
  WHERE logicalrelid = &#39;events&#39;::regclass AND shardlength &lt; 1024*1024*1024
  GROUP BY shardid ORDER BY RANDOM() ASC;

  IF num_small_shards IS NULL OR num_small_shards &lt; 20 THEN
    SELECT master_create_empty_shard(&#39;events&#39;) INTO shard_id;
  END IF;

  RETURN shard_id;
END;
$function$;
</pre></div>
</div>
<p>A drawback of ingesting into many shards concurrently is that shards may span longer time ranges, which means that queries for a specific time period may involve shards that contain a lot of data outside of that period.</p>
<p>In addition to copying into temporary staging tables, it is also possible to set up tables on the workers which can continuously take INSERTs. In that case, the data has to be periodically moved into a staging table and then appended, but this requires more advanced scripting.</p>
</div>
<div class="section" id="pre-processing-data-in-citus">
<h3>Pre-processing Data in Citus<a class="headerlink" href="#pre-processing-data-in-citus" title="Permalink to this headline">¶</a></h3>
<p>The format in which raw data is delivered often differs from the schema used in the database. For example, the raw data may be in the form of log files in which every line is a JSON object, while in the database table it is more efficient to store common values in separate columns. Moreover, a distributed table should always have a distribution column. Fortunately, PostgreSQL is a very powerful data processing tool. You can apply arbitrary pre-processing using SQL before putting the results into a staging table.</p>
<p>For example, assume we have the following table schema and want to load the compressed JSON logs from <a class="reference external" href="http://www.githubarchive.org">githubarchive.org</a>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">github_events</span>
<span class="p">(</span>
    <span class="n">event_id</span> <span class="n">bigint</span><span class="p">,</span>
    <span class="n">event_type</span> <span class="n">text</span><span class="p">,</span>
    <span class="n">event_public</span> <span class="n">boolean</span><span class="p">,</span>
    <span class="n">repo_id</span> <span class="n">bigint</span><span class="p">,</span>
    <span class="n">payload</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">repo</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">actor</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">org</span> <span class="n">jsonb</span><span class="p">,</span>
    <span class="n">created_at</span> <span class="n">timestamp</span>
<span class="p">);</span>
<span class="n">SELECT</span> <span class="n">master_create_distributed_table</span><span class="p">(</span><span class="s1">&#39;github_events&#39;</span><span class="p">,</span> <span class="s1">&#39;created_at&#39;</span><span class="p">,</span> <span class="s1">&#39;append&#39;</span><span class="p">);</span>
</pre></div>
</div>
<p>To load the data, we can download the data, decompress it, filter out unsupported rows, and extract the fields in which we are interested into a staging table using 3 commands:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">CREATE</span> <span class="n">TEMPORARY</span> <span class="n">TABLE</span> <span class="n">prepare_1</span> <span class="p">(</span><span class="n">data</span> <span class="n">jsonb</span><span class="p">);</span>

<span class="o">--</span> <span class="n">Load</span> <span class="n">a</span> <span class="n">file</span> <span class="n">directly</span> <span class="kn">from</span> <span class="nn">Github</span> <span class="n">archive</span> <span class="ow">and</span> <span class="nb">filter</span> <span class="n">out</span> <span class="n">rows</span> <span class="k">with</span> <span class="n">unescaped</span> <span class="mi">0</span><span class="o">-</span><span class="nb">bytes</span>
<span class="n">COPY</span> <span class="n">prepare_1</span> <span class="n">FROM</span> <span class="n">PROGRAM</span>
<span class="s1">&#39;curl -s http://data.githubarchive.org/2016-01-01-15.json.gz | zcat | grep -v &quot;</span><span class="se">\\</span><span class="s1">u0000&quot;&#39;</span>
<span class="n">CSV</span> <span class="n">QUOTE</span> <span class="n">e</span><span class="s1">&#39;</span><span class="se">\x01</span><span class="s1">&#39;</span> <span class="n">DELIMITER</span> <span class="n">e</span><span class="s1">&#39;</span><span class="se">\x02</span><span class="s1">&#39;</span><span class="p">;</span>

<span class="o">--</span> <span class="n">Prepare</span> <span class="n">a</span> <span class="n">staging</span> <span class="n">table</span>
<span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">stage_1</span> <span class="n">AS</span>
<span class="n">SELECT</span> <span class="p">(</span><span class="n">data</span><span class="o">-&gt;&gt;</span><span class="s1">&#39;id&#39;</span><span class="p">)::</span><span class="n">bigint</span> <span class="n">event_id</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;&gt;</span><span class="s1">&#39;type&#39;</span><span class="p">)</span> <span class="n">event_type</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;&gt;</span><span class="s1">&#39;public&#39;</span><span class="p">)::</span><span class="n">boolean</span> <span class="n">event_public</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="s1">&#39;repo&#39;</span><span class="o">-&gt;&gt;</span><span class="s1">&#39;id&#39;</span><span class="p">)::</span><span class="n">bigint</span> <span class="n">repo_id</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="s1">&#39;payload&#39;</span><span class="p">)</span> <span class="n">payload</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="s1">&#39;actor&#39;</span><span class="p">)</span> <span class="n">actor</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;</span><span class="s1">&#39;org&#39;</span><span class="p">)</span> <span class="n">org</span><span class="p">,</span>
       <span class="p">(</span><span class="n">data</span><span class="o">-&gt;&gt;</span><span class="s1">&#39;created_at&#39;</span><span class="p">)::</span><span class="n">timestamp</span> <span class="n">created_at</span> <span class="n">FROM</span> <span class="n">prepare_1</span><span class="p">;</span>
</pre></div>
</div>
<p>You can then use the master_append_table_to_shard function to append this staging table to the distributed table.</p>
<p>This approach works especially well when staging data via the workers, since the pre-processing itself can be scaled out by running it on many workers in parallel for different chunks of input data.</p>
<p>For a more complete example, see <a class="reference external" href="https://www.citusdata.com/blog/14-marco/402-interactive-analytics-github-data-using-postgresql-citus">Interactive Analytics on GitHub Data using PostgreSQL with Citus</a>.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../faq/faq.html" class="btn btn-neutral float-right" title="Frequently Asked Questions" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="configuration.html" class="btn btn-neutral" title="Configuration Reference" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Citus Data.

    </p>
  </div> 

</footer>

          <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-32858865-1', 'auto');
  ga('send', 'pageview');

</script>
<script>
/**
* Function that tracks a click on an outbound link in Analytics.
* This function takes a valid URL string as an argument, and uses that URL string
* as the event label. Setting the transport method to 'beacon' lets the hit be sent
* using 'navigator.sendBeacon' in browser that support it.
*/
var trackOutboundLink = function(url) {
   ga('send', 'event', 'outbound', 'click', url, {
     'transport': 'beacon',
     'hitCallback': function(){document.location = url;}
   });
}
</script>

        </div>
      </div>

    </section>

  </div>
  
<h3>Versions</h3>
<ul>
    <li><a href="../v5.2/reference/append.html">v5.2</a></li>
</ul>

  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'5.2.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>